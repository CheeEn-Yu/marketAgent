{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "# To use model\n",
    "llm = VertexAI(model_name=\"gemini-1.5-pro\")\n",
    "prompt = \"You are a helpful assistant.\"\n",
    "agent_executor = create_react_agent(llm, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, TypedDict, Annotated\n",
    "from datetime import datetime\n",
    "from langgraph.graph import Graph, StateGraph\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "class AnalysisState(TypedDict):\n",
    "    csv_path: str\n",
    "    transcript_path: str\n",
    "    data_analysis: Dict | None\n",
    "    transcript_analysis: Dict | None\n",
    "    visualizations: List[Dict] | None\n",
    "    report_path: str | None\n",
    "\n",
    "class ReportGeneratorAgent:\n",
    "    def __init__(self):\n",
    "        self.model = VertexAI(model_name=\"gemini-1.5-pro\")\n",
    "        self.tools = self._create_tools()\n",
    "        self.graph = self._create_graph()\n",
    "    \n",
    "    def _create_tools(self):\n",
    "        return {\n",
    "            \"analyze_data\": self._analyze_csv_data,\n",
    "            \"analyze_transcript\": self._analyze_transcript,\n",
    "            \"create_visualization\": self._create_visualization,\n",
    "            \"generate_report\": self._generate_final_report\n",
    "        }\n",
    "    \n",
    "    def _analyze_csv_data(self, state: AnalysisState) -> AnalysisState:\n",
    "        \"\"\"分析 CSV 數據\"\"\"\n",
    "        df = pd.read_csv(state[\"csv_path\"])\n",
    "        \n",
    "        # 基本統計分析\n",
    "        analysis = {\n",
    "            \"row_count\": len(df),\n",
    "            \"column_count\": len(df.columns),\n",
    "            \"numerical_columns\": df.select_dtypes(include=['float64', 'int64']).columns.tolist(),\n",
    "            \"categorical_columns\": df.select_dtypes(include=['object']).columns.tolist(),\n",
    "            \"basic_stats\": df.describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        state[\"data_analysis\"] = analysis\n",
    "        return state\n",
    "    \n",
    "    def _analyze_transcript(self, state: AnalysisState) -> AnalysisState:\n",
    "        \"\"\"分析逐字稿內容\"\"\"\n",
    "        with open(state[\"transcript_path\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            transcript = f.read()\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        請分析以下逐字稿的主要內容，提供：\n",
    "        1. 主要主題\n",
    "        2. 關鍵觀點\n",
    "        3. 重要數據或引用\n",
    "        \n",
    "        逐字稿內容：\n",
    "        {transcript}\n",
    "        \n",
    "        請以 JSON 格式回傳分析結果。\n",
    "        \"\"\"\n",
    "        response_schema = {\n",
    "            \"type\": \"ARRAY\",\n",
    "            \"items\": {\n",
    "                \"type\": \"OBJECT\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\"type\": \"STRING\"},\n",
    "                    \"critical_point\": {\"type\": \"ARRAY\", \"items\": {\"type\": \"STRING\"}},\n",
    "                },\n",
    "                \"required\": [\"topic\", \"critical_point\"],\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        response = self.model.client.generate_content(\n",
    "            prompt,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\", response_schema=response_schema\n",
    "            ),\n",
    "        )\n",
    "        analysis = json.loads(response.text)\n",
    "        \n",
    "        state[\"transcript_analysis\"] = analysis\n",
    "        return state\n",
    "    \n",
    "    def _create_visualization(self, state: AnalysisState) -> AnalysisState:\n",
    "        \"\"\"根據數據創建視覺化圖表\"\"\"\n",
    "        df = pd.read_csv(state[\"csv_path\"])\n",
    "        visualizations = []\n",
    "        \n",
    "        # 為數值型列創建圖表\n",
    "        for col in state[\"data_analysis\"][\"numerical_columns\"]:\n",
    "            # 時間序列圖\n",
    "            if \"date\" in col.lower() or \"time\" in col.lower():\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(df[col], df[state[\"data_analysis\"][\"numerical_columns\"][1]])\n",
    "                plt.title(f\"{col} Trend Analysis\")\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # 保存圖表\n",
    "                fig_path = f\"visualization_{len(visualizations)}.png\"\n",
    "                plt.savefig(fig_path)\n",
    "                plt.close()\n",
    "                visualizations.append({\"type\": \"trend\", \"path\": fig_path})\n",
    "            \n",
    "            # 分布圖\n",
    "            else:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.histplot(data=df, x=col)\n",
    "                plt.title(f\"{col} Distribution\")\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                fig_path = f\"visualization_{len(visualizations)}.png\"\n",
    "                plt.savefig(fig_path)\n",
    "                plt.close()\n",
    "                visualizations.append({\"type\": \"distribution\", \"path\": fig_path})\n",
    "        \n",
    "        state[\"visualizations\"] = visualizations\n",
    "        return state\n",
    "    \n",
    "    def _generate_final_report(self, state: AnalysisState) -> AnalysisState:\n",
    "        \"\"\"生成最終報告\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        請根據以下資訊生成一份完整的分析報告：\n",
    "        \n",
    "        1. 數據分析結果：\n",
    "        {json.dumps(state[\"data_analysis\"], indent=2, ensure_ascii=False)}\n",
    "        \n",
    "        2. 逐字稿分析：\n",
    "        {json.dumps(state[\"transcript_analysis\"], indent=2, ensure_ascii=False)}\n",
    "        \n",
    "        3. 已生成的視覺化圖表：\n",
    "        {json.dumps(state[\"visualizations\"], indent=2, ensure_ascii=False)}\n",
    "        \n",
    "        請生成一份結構完整的報告，包含：\n",
    "        - 執行摘要\n",
    "        - 數據分析發現\n",
    "        - 逐字稿重點\n",
    "        - 結論與建議\n",
    "        \n",
    "        格式要求：Markdown格式\n",
    "        \"\"\"\n",
    "        \n",
    "        report = self.model.predict(prompt)\n",
    "        \n",
    "        # 保存報告\n",
    "        report_path = f\"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        state[\"report_path\"] = report_path\n",
    "        return state\n",
    "    \n",
    "    def _create_graph(self) -> Graph:\n",
    "        \"\"\"創建工作流程圖\"\"\"\n",
    "        # 使用定義的 AnalysisState 作為 schema\n",
    "        workflow = StateGraph(state_schema=AnalysisState)\n",
    "        \n",
    "        # 添加節點\n",
    "        workflow.add_node(\"analyze_data\", self._analyze_csv_data)\n",
    "        workflow.add_node(\"analyze_transcript\", self._analyze_transcript)\n",
    "        workflow.add_node(\"create_visualization\", self._create_visualization)\n",
    "        workflow.add_node(\"generate_report\", self._generate_final_report)\n",
    "        \n",
    "        # 設定工作流程\n",
    "        workflow.set_entry_point(\"analyze_data\")\n",
    "        workflow.add_edge(\"analyze_data\", \"analyze_transcript\")\n",
    "        workflow.add_edge(\"analyze_transcript\", \"create_visualization\")\n",
    "        workflow.add_edge(\"create_visualization\", \"generate_report\")\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    def generate_report(self, csv_path: str, transcript_path: str) -> str:\n",
    "        \"\"\"執行報告生成流程\"\"\"\n",
    "        initial_state: AnalysisState = {\n",
    "            \"csv_path\": csv_path,\n",
    "            \"transcript_path\": transcript_path,\n",
    "            \"data_analysis\": None,\n",
    "            \"transcript_analysis\": None,\n",
    "            \"visualizations\": None,\n",
    "            \"report_path\": None\n",
    "        }\n",
    "        \n",
    "        # 執行工作流程\n",
    "        final_state = self.graph.invoke(initial_state)\n",
    "        \n",
    "        return final_state[\"report_path\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated at: report_20250214_225627.md\n"
     ]
    }
   ],
   "source": [
    "agent = ReportGeneratorAgent()\n",
    "report_path = agent.generate_report(\n",
    "    csv_path=\"FIN_data.csv\",\n",
    "    transcript_path=\"test.txt\"\n",
    ")\n",
    "print(f\"Report generated at: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
